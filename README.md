# Natural Policy Gradient for Low Rank MDP with log-linear Parametrization

## 1. Introduction

### 1.1 Background and Motivation

It was well-established that, for `tabular softmax parametrization`, `natural policy gradient` method can obtain `linear convergence rate` with `geometrically increasing step-size`.

Recent findings suggest that, for `log-linear policy parametrization`, `natural policy gradient` method can also obtain `linear rate` with `geometrically increasing step-size`, _given_ that the environment has a `low-rank structure`.

### 1.2 Tasks of this Project

**Topics:** _Reinforcement Learning_, _Natural Policy Gradient_, _Markov Decision Process (MDP)_

**Skills:** _Python_, _JAX_, _Numpy_, _Jupyter Lab_, _Colab_

## 2. Reference
